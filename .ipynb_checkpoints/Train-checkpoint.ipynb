{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLJ8mAVVo4Ye"
   },
   "outputs": [],
   "source": [
    "#### Author: Arman Kabiri\n",
    "#### Date: Feb. 18, 2020\n",
    "#### Email: Arman.Kabiri94@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5749,
     "status": "ok",
     "timestamp": 1587161327069,
     "user": {
      "displayName": "Arman Kabiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhEhmp3MUuNcUVj9CDTifSEk2lm_aME6fhPGB-=s64",
      "userId": "08040985308833979547"
     },
     "user_tz": 180
    },
    "id": "R4GU9bOKlZgy",
    "outputId": "5eafbaa1-7f32-43a1-bcf6-3bd5e5ff78b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n",
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardcolab\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uK1Na68GmLMb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/gdrive/My Drive/NLP_Stuff/My_Language_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4342,
     "status": "ok",
     "timestamp": 1587162632472,
     "user": {
      "displayName": "Arman Kabiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhEhmp3MUuNcUVj9CDTifSEk2lm_aME6fhPGB-=s64",
      "userId": "08040985308833979547"
     },
     "user_tz": 180
    },
    "id": "Rxgh43k2Q7nQ",
    "outputId": "7f0fb8c8-c4e5-4e49-a345-9f8f49c4a71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboardcolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZ_wEUt9iBfV"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os.path as path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from tensorboardcolab import TensorBoardColab\n",
    "# tb = TensorBoardColab()\n",
    "\n",
    "from CorpusReader import CorpusReader\n",
    "from Dictionary import Dictionary\n",
    "from EmbeddingsLoader import EmbeddingsLoader\n",
    "from Lang_Model import LanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsk3Vi1xf8i9"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "  corpus_train_file='Data/WestburyLab.Wikipedia.Corpus_AdagramTokenized.txt'\n",
    "  corpus_valid_file=''\n",
    "  embeddings_file='Data/English_Wiki_1Billion_embeddings.bin'\n",
    "  output_model_path='Data/model.bin'\n",
    "  output_id2word_path = 'Data/id2word.txt'\n",
    "  output_word2id_path = 'Data/word2id.txt'\n",
    "  n_layers=2\n",
    "  hidden_size=300\n",
    "  dropout_probablity=.25\n",
    "  embeddings_dim=300\n",
    "  batch_size=64\n",
    "  seq_len=10\n",
    "  epochs=2\n",
    "  lr=0.001\n",
    "  seed=120\n",
    "  clip_grad = 5\n",
    "  print_steps=20\n",
    "  bidirectional_model=False\n",
    "  tie_weights=False\n",
    "  freez_embeddings=False\n",
    "  gpu=True\n",
    "  \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17477,
     "status": "ok",
     "timestamp": 1587153988467,
     "user": {
      "displayName": "Arman Kabiri",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhhEhmp3MUuNcUVj9CDTifSEk2lm_aME6fhPGB-=s64",
      "userId": "08040985308833979547"
     },
     "user_tz": 180
    },
    "id": "PYPZK2k9qLEA",
    "outputId": "bddbb35c-49ad-4a17-8a39-f6515545b196",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5wQiUSMf1mM"
   },
   "outputs": [],
   "source": [
    "def train(corpus_train_reader, dictionary, model, optimizer, criterion, args, globaliter=0):\n",
    "    batch_generator = corpus_train_reader.batchify(dictionary, args.batch_size, args.seq_len)\n",
    "    hidden = model.init_hidden(args.batch_size)\n",
    "\n",
    "    step = 0\n",
    "    for x, y in tqdm(batch_generator):\n",
    "\n",
    "        step += 1\n",
    "        globaliter += 1\n",
    "        x = torch.from_numpy(x)\n",
    "        y = torch.from_numpy(y)\n",
    "\n",
    "        if args.gpu:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        hidden = detach_hidden(hidden)\n",
    "        model.zero_grad()\n",
    "\n",
    "        y_hat, hidden = model.forward(x, hidden)\n",
    "\n",
    "        loss = criterion.forward(y_hat.view(-1, dictionary.get_dic_size()),\n",
    "                                 y.reshape(args.batch_size * args.seq_len).long())\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=args.clip_grad)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % args.print_steps == 0:\n",
    "            print(f\"Step {step} ,     epoch progress = {corpus_train_reader.get_progress()}% ,     Loss = {loss.item()} ,    PPL = {np.exp(loss.item())}\")\n",
    "            tb.save_value('Train Loss', 'train_loss', args.globaliter, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STyC9SB4f1mQ"
   },
   "outputs": [],
   "source": [
    "def detach_hidden(hidden: tuple):\n",
    "    return tuple(v.detach() for v in hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "204l3oEef1mT"
   },
   "outputs": [],
   "source": [
    "def save_dictionary(dictionary: Dictionary, output_id2word_path, output_word2id_path):\n",
    "    with open(output_word2id_path, 'w') as file:\n",
    "        for word, word_id in dictionary.word2id.items():\n",
    "            if '\\t' in word:\n",
    "                exit()\n",
    "            file.write(f\"{word}\\t{word_id}\\n\")\n",
    "\n",
    "    with open(output_id2word_path, 'w') as file:\n",
    "        for word in dictionary.id2word:\n",
    "            file.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bT7ytKqnj2_J"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    torch.set_num_threads(8)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        if not args.gpu:\n",
    "            print(\"WARNING: You have a CUDA device, so you should probably run with --gpu\")\n",
    "    else:\n",
    "        if args.gpu:\n",
    "            print(\"You do not have a GPU device, so you should run CPU without --gpu option.\")\n",
    "            exit()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    corpus_train_reader = CorpusReader(args.corpus_train_file, 100000000)  # 100MB\n",
    "    \n",
    "    dictionary = Dictionary()\n",
    "    \n",
    "    # Load the pre-trained Model for fine-tuning\n",
    "    if path.exists(args.output_model_path):\n",
    "        print(\"Loading Dictionaries...\")\n",
    "        dictionary.load_dictionary(id2word_filepath=args.output_id2word_path, word2id_filepath=args.output_word2id_path)\n",
    "        print(\"Loading pre-trained Model...\")\n",
    "        model = LanguageModel(path_to_pretrained_model=args.output_model_path, use_gpu=args.gpu)\n",
    "    \n",
    "    # Initialize the model\n",
    "    else:\n",
    "        print(\"Generating Dictionaries...\")\n",
    "        dictionary.build_dictionary(corpus_train_reader)\n",
    "\n",
    "        print(\"Saving Dictionary...\")\n",
    "        save_dictionary(dictionary, args.output_id2word_path, args.output_word2id_path)\n",
    "\n",
    "        print(\"Loading Embeddings...\")\n",
    "        embeddings_matrix = None\n",
    "        if args.embeddings_file is not None:\n",
    "            emb_loader = EmbeddingsLoader()\n",
    "            embeddings_matrix = emb_loader.get_embeddings_matrix(args.embeddings_file, dictionary, args.embeddings_dim)\n",
    "\n",
    "        model = LanguageModel(n_layers=args.n_layers, hidden_size=args.hidden_size, n_vocab=dictionary.get_dic_size(),\n",
    "                              input_size=args.embeddings_dim, dropout_prob=args.dropout_probablity,\n",
    "                              bidirectional=args.bidirectional_model, pret_emb_matrix=embeddings_matrix,\n",
    "                              freez_emb=args.freez_embeddings, tie_weights=args.tie_weights, use_gpu=args.gpu)\n",
    "\n",
    "    ###############\n",
    "    total_param = []\n",
    "    for p in model.parameters():\n",
    "        total_param.append(int(p.numel()))\n",
    "    print(f\"Number of Parametes: {sum(total_param)}\\n\")\n",
    "    ###############\n",
    "\n",
    "\n",
    "    # put it into train mode.\n",
    "    model.train()\n",
    "    if args.gpu:\n",
    "        model.cuda()\n",
    "\n",
    "    # Optimizer and Loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    #Training Model\n",
    "    print(\"Training Model...\")\n",
    "    args.globaliter = 0\n",
    "    for i in range(args.epochs):\n",
    "        print(f\"Epoch {i + 1}:\")\n",
    "        train(corpus_train_reader, dictionary, model, optimizer, criterion, args)\n",
    "        print(f\"Saving Model at epoch {i + 1}...\")\n",
    "        model.save_model(args.output_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "n1_v7GmdtvzB",
    "outputId": "1c627889-ed5e-40e9-cf1e-73d4fc2ffb2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Dictionaries...\n",
      "Building dictionaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [03:56,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionaries are built - Vocab size is 3825945\n",
      "Saving Dictionary...\n",
      "Loading Embeddings...\n",
      "Loading pretrained embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained embeddings are loaded.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Htc-6NOBgHjC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
